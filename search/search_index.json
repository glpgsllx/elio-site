{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Elio AI Hub","text":"<p>\u6b22\u8fce\u6765\u5230\u6211\u7684 AI \u5de5\u7a0b\u4e0e\u7814\u7a76\u4e3b\u9875\uff0c\u8fd9\u91cc\u8bb0\u5f55\u957f\u671f\u9879\u76ee\u3001\u7814\u7a76\u6d1e\u89c1\u4e0e\u6210\u957f\u8db3\u8ff9\u3002</p> <p>\u4e0e\u6211\u8054\u7cfb\uff1a GitHub \u00b7 LinkedIn \u00b7 Email</p>"},{"location":"about/","title":"About Me","text":"<p>\u7b80\u8981\u4ecb\u7ecd\u6211\u7684\u7814\u7a76\u80cc\u666f\u3001\u5174\u8da3\u4e0e\u5f53\u524d\u805a\u7126\u65b9\u5411\u3002</p>"},{"location":"about/#_1","title":"\u8054\u7cfb\u65b9\u5f0f","text":"<ul> <li>GitHub: glpgsllx</li> <li>Email: chenyixuan1120@gmail.com</li> <li>LinkedIn: Yixuan Chen</li> </ul>"},{"location":"interviews/","title":"Interviews","text":"<p>\u6c42\u804c\u4e0e\u9762\u8bd5\u51c6\u5907\u7684\u77e5\u8bc6\u5e93\uff0c\u8986\u76d6\u7b97\u6cd5\u3001\u7cfb\u7edf\u3001ML \u4e0e LLM \u5c97\u4f4d\u3002</p>"},{"location":"interviews/algo/","title":"Algorithm Prep","text":"<p>\u6574\u7406\u5e38\u89c1\u7b14\u8bd5\u9898\u578b\u3001\u6570\u636e\u7ed3\u6784\u6a21\u677f\u4e0e\u590d\u6742\u5ea6\u5206\u6790\u8981\u70b9\u3002</p>"},{"location":"interviews/llm-engineer/","title":"LLM Engineer Prep","text":"<p>\u805a\u7126\u63d0\u793a\u5de5\u7a0b\u3001Serving \u67b6\u6784\u4e0e\u63a8\u7406\u4f18\u5316\u76f8\u5173\u7684\u73b0\u573a\u8003\u5bdf\u8bdd\u9898\u3002</p>"},{"location":"interviews/machine-learning/","title":"Machine Learning Prep","text":"<p>\u603b\u7ed3\u6a21\u578b\u9009\u62e9\u3001\u6b63\u5219\u5316\u3001\u8bad\u7ec3\u8c03\u4f18\u4e0e\u6848\u4f8b\u5206\u6790\u9762\u8bd5\u9898\u3002</p>"},{"location":"interviews/project-review/","title":"Project Review Prep","text":"<p>\u68b3\u7406\u4ee3\u8868\u6027\u9879\u76ee\u7684\u8bb2\u8ff0\u7ed3\u6784\u3001\u6307\u6807\u4eae\u70b9\u4e0e\u590d\u76d8\u601d\u7ef4\u3002</p>"},{"location":"interviews/system-design/","title":"System Design Prep","text":"<p>\u6c89\u6dc0\u540e\u7aef\u67b6\u6784\u3001\u5206\u5e03\u5f0f\u7ec4\u4ef6\u4e0e\u5bb9\u91cf\u89c4\u5212\u9898\u76ee\u7684\u601d\u8def\u4e0e\u56fe\u89e3\u3002</p>"},{"location":"notes/","title":"Notes","text":"<p>\u5b66\u4e60\u7b14\u8bb0\u603b\u89c8\uff0c\u8bb0\u5f55 AI \u7cfb\u7edf\u3001\u6a21\u578b\u4e0e\u5de5\u7a0b\u5b9e\u8df5\u7684\u8981\u70b9\u3002</p>"},{"location":"notes/attention-variants/","title":"Attention Variants","text":"<p>\u6536\u5f55\u7ebf\u6027\u6ce8\u610f\u529b\u3001FlashAttention \u4ee5\u53ca\u5176\u4ed6\u9ad8\u6548\u6ce8\u610f\u529b\u7ed3\u6784\u7684\u8c03\u7814\u3002</p>"},{"location":"notes/attention-variants/#_1","title":"\u76ee\u5f55","text":"<ul> <li>Linear Attention \u7b14\u8bb0\uff1a\u4ece\u6807\u51c6\u6ce8\u610f\u529b\u516c\u5f0f\u63a8\u5bfc\u5230\u6838\u5206\u89e3\u3001\u72b6\u6001\u7d2f\u52a0\u7684\u76f4\u89c9\u3002</li> <li>MLA\uff08DeepSeek-V2\uff09\uff1a\u4f4e\u79e9 KV \u8054\u5408\u538b\u7f29\u3001KV cache \u5185\u5b58\u5360\u7528\u4e0e\u63a8\u7406\u6027\u80fd\u5206\u6790\u3002</li> </ul>"},{"location":"notes/attention-variants/Linear-Attn%28org%29/","title":"1. \u666e\u901a\u6ce8\u610f\u529b\u7684\u516c\u5f0f\uff08\u6807\u51c6\u7248\uff09","text":"<p>\u6807\u51c6 self-attention\uff1a</p> \\[ \\mathrm{Attn}(Q,K,V) = \\mathrm{softmax}\\!\\left(\\frac{QK^\\top}{\\sqrt{d}}\\right)V \\] <p>\u590d\u6742\u5ea6\uff1a\\(O(n^2d)\\)\uff0c\u56e0\u4e3a \\(QK^\\top\\) \u662f\u4e00\u4e2a \\(n\\times n\\) \u7684\u77e9\u9635\u3002</p>"},{"location":"notes/attention-variants/Linear-Attn%28org%29/#2-linear-attention","title":"2. linear attention \u60f3\u8981\u4ec0\u4e48\uff1f","text":"<p>\u60f3\u628a\u6ce8\u610f\u529b\u5199\u6210\uff1a</p> \\[ \\mathrm{Attn}(Q,K,V)_t = f(Q_t)^\\top\\, S_t \\] <p>\u5176\u4e2d \\(S_t\\) \u662f\u53ef\u7d2f\u52a0\u7684\u72b6\u6001\uff1a</p> \\[ S_t = \\sum_{j=1}^{t} g(K_j, V_j) \\] <ul> <li>\u6bcf\u4e00\u6b65\u53ea\u66f4\u65b0\u4e00\u6b21 \\(S_t\\)</li> <li>\u7136\u540equery\u53ea\u505a\u4e00\u6b21 \\(f(Q_t)^\\top S_t\\)</li> </ul> <p>\u6240\u4ee5\u80fd\u4ece \\(O(n^2)\\) \u53d8\u6210 \\(O(n)\\)\u3002</p>"},{"location":"notes/attention-variants/Linear-Attn%28org%29/#3-linear-attention-kernel-trick","title":"3. linear attention \u7684\u6838\u5206\u89e3\uff08kernel trick\uff09","text":"<p>softmax \u975e\u5e38\u9ecf\uff0c\u4e0d\u53ef\u5206\u89e3\u3002 \u6240\u4ee5\u628a softmax attention \u8fd1\u4f3c\u6210\u4e00\u4e2a \u53ef\u5206\u89e3\u6838\uff1a</p> \\[ \\exp(QK^\\top) \\approx \\phi(Q) \\phi(K)^\\top \\] <p>\u4e8e\u662f\u6ce8\u610f\u529b\u53d8\u6210\uff1a</p> \\[ \\mathrm{Attn}(Q,K,V)_t = \\sum_{j=1}^{t} \\phi(Q_t)^\\top \\phi(K_j)\\, V_j \\] <p>\u628a \\(\\phi(Q_t)\\) \u63d0\u51fa\u6765\uff1a</p> <p>$$ \\mathrm{Attn}(Q,K,V)t = \\phi(Q_t)^\\top \\left( \\sum \\phi(K_j) V_j \\right) $$ \u73b0\u5728\u5b9a\u4e49\uff1a}^{t</p> \\[ S_t = \\sum_{j=1}^{t} \\phi(K_j) V_j \\] <p>\u6700\u7ec8\u5f97\u5230\uff1a</p> <p>$$ \\mathrm{Attn}(Q,K,V)_t = \\phi(Q_t)^\\top S_t $$ \u8fd9\u5c31\u662f linear attention \u6700\u6838\u5fc3\u7684\u7ed3\u6784\u3002</p>"},{"location":"notes/attention-variants/Linear-Attn%28org%29/#4","title":"4. \u4e3a\u4ec0\u4e48\u5b83\u662f\u7ebf\u6027\u7684\uff1f","text":"<p>\u5bf9\u6bcf\u4e2a\u65b0 token\uff0c\u66f4\u65b0\u72b6\u6001\uff1a</p> \\[ S_t = S_{t-1} + \\phi(K_t) V_t \\] <p>\u8ba1\u7b97\u8f93\u51fa\uff1a</p> \\[ O_t = \\phi(Q_t)^\\top S_t \\] <p>\u4e24\u6b65\u90fd\u662f \\(O(d^2)\\) \u7684\uff0c\u6574\u4e2a\u5e8f\u5217\u957f\u5ea6 \\(n\\) \u2192 \u603b\u590d\u6742\u5ea6 \\(O(nd^2)\\)\u3002 \u76f8\u6bd4\u539f\u672c\u7684 \\(O(n^2d)\\)\uff0c\u7701\u4e86\u4e00\u4e2a \\(n\\)\u3002</p>"},{"location":"notes/attention-variants/Linear-Attn%28org%29/#5-kv-linear-attention","title":"** 5. \u4e3a\u4ec0\u4e48\u201c\u628a\u4f4d\u7f6e\u4fe1\u606f\u52a0\u5230 K/V \u91cc\u4f1a\u7834\u574f linear attention\u201d\uff1f**","text":"<p>\u56e0\u4e3a linear attention \u7684\u7d2f\u52a0\u9879\u8981\u6c42\uff1a</p> \\[ S_t = \\sum_{j=1}^{t} \\phi(K_j) V_j \\] <p>\u5fc5\u987b\u6ee1\u8db3\uff1a</p> <ul> <li>\\(\\phi(K_j)\\) \u53ef\u7d2f\u52a0</li> <li>\\(\\phi(K_j)\\) \u4e0d\u968f\u7740 t \u518d\u53d1\u751f\u53d8\u5316</li> <li>\u4f4d\u7f6e\u7f16\u7801\u4e0d\u80fd\u8ba9 \\(K_j\\) \u53d8\u5f97\u4e0d\u53ef\u5206\u89e3 \u5982\u679c\u4f60\u628a\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u76f4\u63a5\u52a0\u5230 K \u4e0a\uff1a</li> </ul> \\[ K_j' = K_j + \\text{pos}_j \\] <p>\u90a3\u4e48\uff1a</p> \\[ S_t = \\sum_{j=1}^t \\phi(K_j + \\text{pos}_j)V_j \\] <p>\u8fd9\u4e2a\u7ed3\u6784\u901a\u5e38 \u4e0d\u53ef\u5206\u89e3\uff0c\u4e5f\u4e0d\u80fd\u5199\u6210\u201c\u5185\u5bb9 \u00d7 \u4f4d\u7f6e\u201d\u7684\u5f62\u5f0f\uff0c\u4f1a\u5bfc\u81f4\uff1a</p> <ul> <li>\u72b6\u6001 S \u5931\u6548</li> <li>prefix \u4e0d\u80fd\u7f13\u5b58</li> <li>\u5fc5\u987b\u91cd\u65b0\u7b97\u6240\u6709 K_j</li> </ul> <p>\u4e8e\u662f\uff1alinear attention architecture \u65e0\u6cd5\u5de5\u4f5c\u3002</p> <p>\u5bf9\u4e8e\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u901a\u5e38 \\(\\phi(K_j + p_j)\\neq \\phi(K_j)+\\phi(p_j)\\)\uff0c\u6240\u6709\u4f4d\u7f6e\u4fe1\u606f\u4f1a\u6df7\u5728\u4e00\u8d77\u3002 \u5bf9\u4e8e\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\\(\\mathrm{score}(t,j)=Q_t^\\top K_j + Q_t^\\top a_{t-j}\\)\uff0c\u8981\u5bf9 \\(a_{t-j}\\) \u505a\u5b9e\u65f6\u66f4\u65b0\uff0c\u7d2f\u52a0\u72b6\u6001\u65e0\u6cd5\u6784\u5efa\u3002</p>"},{"location":"notes/attention-variants/MLA/","title":"MLA","text":"<p>From DeepSeek-V2</p> <p>MLA, which utilizes low-rank key-value joint compression to eliminate the bottleneck of inference-time key-value cache, thus supporting efficient inference.</p> <p> MHA-&gt;heavy KV cache -&gt; MQA and GQA, require a smaller magnitude of KV Cache, but performance does not match MHA </p>"},{"location":"notes/attention-variants/MLA/#1-mha","title":"1. MHA","text":"<p>\\(h_t \\in \\mathbb{R}^d\\), the attention input of the t-th token at an attn layer. \\(q_t, k_t, v_t \\in \\mathbb{R}^{d_h n_h}\\) ,  \\(W^Q, W^K, W^V \\in \\mathbb{R}^{d_h n_h \\times d}\\), \\(d_h\\) is the dimension per head, \\(n_h\\) is the number of heads. $$ q_t = W^Q h_t, k_t = W^K h_t, v_t = W^V h_t $$ then  \\(W^O \\in \\mathbb{R}^{d \\times d_h n_h}\\) denotes the output proj matrix All k and v need to be cached, so MHA needs to cache</p> \\[ 2 n_h d_h l  \\] <p>elements for each token.</p> <p>In model deployment, this heavy KV cache is a large bottleneck that limits the maximum batch size and sequence length.</p>"},{"location":"notes/attention-variants/MLA/#2-low-rank-k-v-joint-compression","title":"2. Low-Rank K-V Joint Compression","text":"<p>The core of MLA is the low-rank joint compression for keys and values to reduce KV cache. $$ \\begin{gather} c_t^{KV} = W^{DKV}h_t, \\; \\in \\mathbb{R}^{d_c} \\ k_t^{C} = W^{UK}c_t^{KV}, \\; \\in \\mathbb{R}^{d_n h_n} \\ v_t^{C} = W^{UV}c_t^{KV}, \\; \\in \\mathbb{R}^{d_n h_n}  \\end{gather} $$ \u7b2c\u4e00\u6b65\u662f\u538b\u7f29\uff0c\\(d_c &lt;&lt; d_h n_h\\) \u7b2c\u4e8c\u6b65\u662f up_projection\uff0c\u6062\u590d\u6210 \\(d_h n_h\\) \u5b58\u50a8\u7684\u65f6\u5019\u53ea\u8981\u5b58 \\(c_t^{KV}, \\quad d_c l\\) elements, \\(l\\) denotes the number of layers</p> <p>\\(\ud835\udc4a^{\ud835\udc48\ud835\udc3e}\\) can be absorbed into \\(\ud835\udc4a^\ud835\udc44\\), and \\(\ud835\udc4a^{\ud835\udc48\ud835\udc49}\\) can be absorbedinto \\(\ud835\udc4a^\ud835\udc42\\)</p> <p>\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u4e3a\u4e86 reduce the activation memory, \u5bf9query \u4e5f\u4f7f\u7528 low-rank compression, \u5373\u4f7f\u4e0d\u4f1a\u51cf\u5c11 KV cache $$ \\begin{gather} c_t^{Q} = W^{DQ}h_t, \\; \\in \\mathbb{R}^{d_c'} \\ q_t^{C} = W^{UQ}c_t^{Q}, \\; \\in \\mathbb{R}^{d_n h_n} \\ \\end{gather} $$ \\(d_c' &lt;&lt; d_h n_h\\)</p>"},{"location":"notes/attention-variants/MLA/#3-decoupled-rotary-position-embedding","title":"3. Decoupled Rotary Position Embedding","text":""},{"location":"notes/efficient-inference/","title":"Efficient Inference","text":"<p>\u8bb0\u5f55 vLLM\u3001PagedAttention \u4e0e KV Cache \u7b49\u9ad8\u6548\u63a8\u7406\u65b9\u6848\u7684\u5206\u6790\u4e0e\u5b9e\u8df5\u3002</p>"},{"location":"notes/miscellaneous/","title":"Miscellaneous Notes","text":"<p>\u8bb0\u5f55\u96f6\u6563\u4f46\u6709\u4ef7\u503c\u7684\u5b9e\u9a8c\u3001\u811a\u672c\u4e0e\u7075\u611f\u3002</p>"},{"location":"notes/positional-encodings/","title":"Positional Encodings","text":"<p>\u8ddf\u8e2a RoPE\u3001\u8fde\u7eed\u4f4d\u7f6e\u7f16\u7801\u4e0e\u76f8\u5173\u7406\u8bba\u63a8\u5bfc\u7684\u63a8\u6f14\u4e0e\u9a8c\u8bc1\u3002</p>"},{"location":"notes/positional-encodings/#_1","title":"\u7b14\u8bb0\u7d22\u5f15","text":"<ul> <li>RoPE\uff1a\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u2014\u2014\u4ece\u51e0\u4f55\u76f4\u89c9\u5230\u4e00\u822c\u5f62\u5f0f\uff0c\u517c\u987e\u516c\u5f0f\u4e0e\u56fe\u793a\u3002</li> </ul>"},{"location":"notes/positional-encodings/RoPE/","title":"RoPE","text":"<p>Despite the effectiveness of these approaches, they commonly add the position information to the context representation and thus render them unsuitable for the linear self-attention architecture. Linear-Attn(org)</p> <p>3\u4e2a\u7279\u6027</p> <ul> <li>sequence length flexibility</li> <li>decaying inter-token dependency with increasing relative distances</li> <li>capability of equipping the linear self-attention with relative position encoding</li> </ul> <p>\u6838\u5fc3\u516c\u5f0f\uff1a $$ q_m = f_q(x_m, m), \\quad k_n = f_k(x_n, n), \\quad v_n = f_v(x_n. n) $$</p>"},{"location":"notes/positional-encodings/RoPE/#1-absolute","title":"1. Absolute","text":"<p> \\(i = 0, 1, 2, \\dots, \\text{sequence length}-1\\) \\(t = 0, 1, 2, \\dots, \\frac{d}{2}-1\\) \\(k = i\\)</p>"},{"location":"notes/positional-encodings/RoPE/#2-relative","title":"2. Relative","text":""},{"location":"notes/positional-encodings/RoPE/#21-self-attention-with-relative-position-representations","title":"2.1 Self-attention with relative position representations","text":"<p>$$ \\begin{aligned} f_q(x_m) := W_qx_m \\ f_k(x_n, n) := W_k(x_n + p_r^k)\\ f_v(x_n, n) := W_v(x_n + p_r^v)\\ \\end{aligned} $$ \\(p_r^k, p_r^v \\in \\mathbb{R}^d\\) are trainable relative position embeddings. \\(r = clip (m\u2212n,r_\\min,r_\\max)\\) represents the relative distance between position m and n.</p>"},{"location":"notes/positional-encodings/RoPE/#22-further-optimization","title":"2.2 Further optimization","text":"<p>change \\(q_m^{\\top} k_n\\) \u5f88\u591a\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u672c\u8d28\u4e0a\u90fd\u662f\u628a\u4f4d\u7f6e embedding\uff08\u65e0\u8bba\u662f\u7edd\u5bf9\u4f4d\u7f6e \\(p_i\\) \u8fd8\u662f\u76f8\u5bf9\u4f4d\u7f6e \\(p_{i\u2212j}\\) \u76f4\u63a5\u52a0\u5230 Q\u3001K\u3001V \u91cc\u9762</p> <p>\u5176\u4e2d\u6548\u7387\u6700\u9ad8\u7684\u662f </p> <p>Deberta: Decoding-enhanced bert with disentangled attention.</p> \\[ q_m^\\top k_n = x_m^\\top W_q^\\top W_k x_n + x_m^\\top W_q^\\top W_k \\,\\tilde p_{\\,m-n} + \\tilde p_{\\,m-n}^\\top W_q^\\top W_k x_n . \\] <ul> <li>\\(\\tilde p_{m-n}\\) \u662f\u76f8\u5bf9\u4f4d\u7f6e embedding\uff08DeBERTa \u4f7f\u7528 disentangled \u65b9\u5f0f\uff09\uff0c</li> <li>\u7b2c\u4e00\u9879\u662f\u201c\u5185\u5bb9\u2013\u5185\u5bb9\u201d\u6ce8\u610f\u529b\uff0c</li> <li>\u7b2c\u4e8c\u9879\u662f\u201c\u5185\u5bb9\u2013\u4f4d\u7f6e\u201d\uff0c</li> <li>\u7b2c\u4e09\u9879\u662f\u201c\u4f4d\u7f6e\u2013\u5185\u5bb9\u201d\u3002</li> </ul> <p>\u5c5e\u4e8e\u201c\u52a0\u6cd5\u578b\u4f4d\u7f6e\u6ce8\u5165\u201d\uff0c\u5bf9\u540e\u7eed\u7684\u7ebf\u6027\u5316\u3001\u81ea\u56de\u5f52\u7f13\u5b58\u7b49\u673a\u5236\u4f9d\u7136\u4e0d\u53cb\u597d[[Linear-Attn(org)]]</p>"},{"location":"notes/positional-encodings/RoPE/#3-rope","title":"3. RoPE","text":"<p>\u5e0c\u671b\u6ce8\u610f\u529b\u5206\u6570 q\u2098\u1d40k\u2099 \u4e0d\u8981\u4f9d\u8d56 token \u5404\u81ea\u7684\u7edd\u5bf9\u4f4d\u7f6e m\u3001n\uff0c\u800c\u53ea\u4f9d\u8d56\u5b83\u4eec\u7684\u201c\u76f8\u5bf9\u4f4d\u7f6e m\u2212n\u201c</p> <p>\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\uff0c\u53ea\u8003\u8651 2 \u4e2a\u8bcd\u5411\u91cf\u548c\u4f4d\u7f6e\u5dee\uff1a</p> \\[ &lt;f_q(x_m, m), f_k(x_n, n)&gt; = g(x_m, x_n, m - n) \\]"},{"location":"notes/positional-encodings/RoPE/#31-2d-case","title":"3.1 2D case","text":"<p>\u5728\u4e8c\u7ef4\u60c5\u5f62\uff08d = 2\uff09\u4e0b\uff0c\u53ef\u4ee5\u5229\u7528\u590d\u6570\u5e73\u9762\u4e0a\u7684\u51e0\u4f55\u6027\u8d28\u6765\u5c55\u793a RoPE \u7684\u6838\u5fc3\u601d\u60f3\u3002</p>"},{"location":"notes/positional-encodings/RoPE/#query-key","title":"\u590d\u6570\u5f62\u5f0f\u7684 Query / Key","text":"<p>\u4ee4\u4f4d\u7f6e\u4e3a m\u3001n \u7684\u5411\u91cf\u7ecf\u8fc7\u7ebf\u6027\u53d8\u6362\u540e\u5206\u522b\u4e3a\uff1a \\(W_q x_m\\) \u548c \\(W_k x_n\\)</p> <p>RoPE \u5c06\u5b83\u4eec\u8868\u793a\u4e3a\u590d\u6570\u5e76\u6309\u4f4d\u7f6e\u8fdb\u884c\u65cb\u8f6c\uff1a</p> \\[ f_q(x_m, m) = (W_q x_m) e^{im\\theta} \\\\ f_k(x_n, n) = (W_k x_n) e^{in\\theta} \\] <p>\u5176\u4e2d \\(\\theta\\) \u662f\u9884\u8bbe\u7684\u975e\u96f6\u5e38\u6570\u3002</p>"},{"location":"notes/positional-encodings/RoPE/#_1","title":"\u76f8\u5bf9\u4f4d\u7f6e\u5982\u4f55\u51fa\u73b0\uff1f","text":"<p>\u6ce8\u610f\u529b\u7684\u6838\u5fc3\u662f\u5185\u79ef\uff1a $$ g(x_m, x_n, m-n) = \\mathrm{Re}\\big[(W_q x_m)(W_k x_n)^* e^{i(m-n)\\theta}\\big] $$ \u8fd9\u91cc\u7684 \\(\\mathrm{Re}(\\cdot)^*\\) \u8868\u793a\u590d\u5171\u8f6d\uff08\\(a+bi\\) \u7684 conjugate complex number \u662f \\(a-bi\\)\uff09\uff0c\u5176\u4f5c\u7528\u662f\u8ba9 Key \u7684\u65cb\u8f6c\u65b9\u5411\u76f8\u53cd\uff08\u52a0\u53d8\u6210\u51cf\uff09\uff0c\u4ece\u800c\u5f97\u5230 \\(m-n\\)\u3002</p>"},{"location":"notes/positional-encodings/RoPE/#_2","title":"\u65cb\u8f6c\u77e9\u9635\u5f62\u5f0f","text":"<p>\u4e8c\u7ef4\u590d\u6570\u65cb\u8f6c\u7b49\u4ef7\u4e8e\u65cb\u8f6c\u77e9\u9635 q\u7684\u65cb\u8f6c\u77e9\u9635\uff1a $$</p> <p>f_{{q,k}}(x_m, m) =</p> <p>\\begin{pmatrix}</p> <p>\\cos m\\theta &amp; -\\sin m\\theta \\</p> <p>\\sin m\\theta &amp; \\cos m\\theta</p> <p>\\end{pmatrix}</p> <p>\\begin{pmatrix}</p> <p>W^{(11)}{{q,k}} &amp; W^{(12)} \\}</p> <p>W^{(21)}{{q,k}} &amp; W^{(22)}}</p> <p>\\end{pmatrix}</p> <p>\\begin{pmatrix}</p> <p>x_m^{(1)} \\</p> <p>x_m^{(2)}</p> <p>\\end{pmatrix}</p> <p>$$ k\u7684\uff0c\u53ea\u8981\u628am\u6362\u6210n</p> <p>\u5728\u4e8c\u7ef4\u7a7a\u95f4\u91cc\uff0c\u5bf9\u8bcd\u5411\u91cf\u505a\u4e00\u6b21\u7ebf\u6027\u53d8\u6362\u540e\uff0c\u518d\u6309\u201c\u4f4d\u7f6e index \u00d7 \u56fa\u5b9a\u89d2\u5ea6\u201d\u65cb\u8f6c\u5b83\u3002</p> <p>\u8fd9\u6837 q\u1d40k \u7684\u7ed3\u679c\u81ea\u7136\u53d8\u6210\u4f9d\u8d56 m\u2212n\uff0c\u4e8e\u662f\u5b9e\u73b0\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u3002</p> <p>\u8fd9\u5c31\u662f RoPE \u7684\u51e0\u4f55\u76f4\u89c9\uff1a\u7528\u65cb\u8f6c\u53d6\u4ee3\u52a0\u6cd5\uff0c\u628a\u7edd\u5bf9\u4f4d\u7f6e\u53d8\u6210\u76f8\u5bf9\u4f4d\u7f6e\u3002</p>"},{"location":"notes/positional-encodings/RoPE/#32-general-form","title":"3.2 General Form","text":"<p>$$  \\Theta = \\left{ \\theta_i=10000^{-2(i-1)/d}, i\\in \\left[ 1,2,\\dots, d/2 \\right] \\right} $$ \u628a\u8fd9\u4e2a\u5f0f\u5b50\u653e\u5728\\(q_m^{\\top} k_n\\) \u4e0a $$ q_m^{\\top} k_n = (R_{\\Theta, m}^d W_qx_m)^{\\top}(R_{\\Theta, n}^d W_kx_n) = x^{\\top}W_q R_{\\Theta, (n-m)}^d W_kx_n $$ \u4ee5\u524d\u7684\u4f4d\u7f6e\u7f16\u7801\u628a\u4f4d\u7f6e \u201c\u52a0\u201d \u5230\u5185\u5bb9\u4e0a\uff0c\u4f1a\u6c61\u67d3\u8bed\u4e49\uff0c\u5e76\u4e14\u8981\u5728\u6ce8\u610f\u529b\u516c\u5f0f\u91cc\u989d\u5916\u52a0\u5165\u590d\u6742\u7684\u76f8\u5bf9\u4f4d\u7f6e\u9879\u3002</p> <p>RoPE \u4f7f\u7528\u7684\u662f \u201c\u4e58\u6cd5\u5f0f\u4f4d\u7f6e\u7f16\u7801\u201d\uff08\u65cb\u8f6c\uff09\uff0c\u65e0\u9700\u4fee\u6539\u6ce8\u610f\u529b\u7ed3\u6784\uff0c\u76f8\u5bf9\u4f4d\u7f6e (n\u2212m) \u4f1a\u81ea\u7136\u5728\u65cb\u8f6c\u4e2d\u51fa\u73b0\u3002</p>"},{"location":"notes/positional-encodings/RoPE/#33-properties","title":"3.3 Properties","text":""},{"location":"notes/positional-encodings/RoPE/#331-long-term-decay","title":"3.3.1 Long-term decay","text":""},{"location":"notes/positional-encodings/RoPE/#332-linear-attention","title":"3.3.2 Linear Attention","text":"<p> \u7528\u7ebf\u6027\u51fd\u6570\uff0c\u6bd4\u5982 \\(\\phi(x) = \\mathrm{elu}(x) + 1\\) \u5206\u6bcd\u4e0d\u53d8\uff0c\u9632\u6b62\u4e3a0</p>"},{"location":"notes/systems/","title":"Systems Notes","text":"<p>\u6db5\u76d6 CUDA \u5b9e\u8df5\u3001\u6027\u80fd\u4f18\u5316\u3001\u7f13\u5b58\u7b56\u7565\u4e0e\u7f16\u8bd1\u8c03\u4f18\u7684\u7ecf\u9a8c\u3002</p>"},{"location":"notes/systems/#_1","title":"\u6df1\u5165\u4e13\u9898","text":"<ul> <li>FlashAttention \u5185\u6838\u62c6\u89e3\uff1a\u8bb0\u5f55 CUDA kernel\u3001tile \u8bbe\u8ba1\u4e0e\u6570\u503c\u7a33\u5b9a\u7b56\u7565\u3002</li> <li>vLLM \u4f53\u7cfb\u7b14\u8bb0\uff1a\u603b\u89c8\u8c03\u5ea6\u67b6\u6784\uff0c\u5e76\u94fe\u63a5\u81f3\u66f4\u7ec6\u7684 KV Cache \u8bb0\u5f55\u3002</li> </ul>"},{"location":"notes/systems/flashattention/kernel-notes/","title":"FlashAttention \u5185\u6838\u62c6\u89e3","text":"<ul> <li>Tile \u4e0e block \u7684\u6620\u5c04\u5173\u7cfb</li> <li>Online Softmax \u6570\u503c\u7a33\u5b9a\u4e0e\u4e2d\u95f4\u7f13\u5b58\u8bbe\u8ba1</li> </ul>"},{"location":"notes/systems/vllm/intro/","title":"vLLM \u4ee3\u7801\u5e93","text":"<p>\u8fd9\u91cc\u4f5c\u4e3a vLLM \u76f8\u5173\u7b14\u8bb0\u7684\u603b\u5165\u53e3\uff0c\u4ece\u6574\u4f53\u67b6\u6784\u51fa\u53d1\uff0c\u94fe\u63a5\u5230\u5404\u4e2a\u6a21\u5757\u62c6\u89e3\u4e0e\u4f18\u5316\u4e13\u9898\u3002</p>"},{"location":"notes/systems/vllm/intro/#_1","title":"\u6a21\u5757\u62c6\u89e3","text":"<ul> <li>Entrypoint\uff1a<code>LLM</code> / API server \u5165\u53e3\u4e0e\u8bf7\u6c42\u751f\u547d\u5468\u671f\u3002</li> <li>Engine\uff1a\u8c03\u5ea6\u6838\u5fc3\u3001\u6267\u884c pipeline \u4e0e\u8d44\u6e90\u7ba1\u7406\u3002</li> <li>Scheduler\uff1a\u8bf7\u6c42\u6392\u961f\u7b56\u7565\u3001chunk/prefill \u8c03\u5ea6\u903b\u8f91\u3002</li> <li>KV Cache Manager\uff1aKV cache \u751f\u547d\u5468\u671f\u3001\u5206\u9875\u4e0e\u56de\u6536\u3002</li> <li>Evictor\uff1aeviction \u7b56\u7565\u3001\u51b7\u70ed\u6570\u636e\u4e0e\u663e\u5b58\u56de\u6536\u3002</li> <li>Worker\uff1aworker \u89d2\u8272\u3001\u4e0e engine \u7684\u901a\u4fe1\u534f\u8bae\u3002</li> <li>Model Executor\uff1a\u6a21\u578b\u524d\u5411\u6267\u884c\u3001batch \u5408\u5e76\u4e0e\u5f20\u91cf\u5e03\u5c40\u3002</li> <li>Modeling\uff1a\u6a21\u578b\u5b9a\u4e49\u3001\u6743\u91cd\u52a0\u8f7d\u4e0e\u4e0e HF/\u539f\u751f\u63a5\u53e3\u7684\u5bf9\u63a5\u3002</li> <li>Attention backend\uff1a\u4e0d\u540c Attention kernel / backend \u7684\u62bd\u8c61\u4e0e\u9009\u62e9\u3002</li> </ul>"},{"location":"notes/systems/vllm/intro/#_2","title":"\u5468\u8fb9\u4e0e\u4f18\u5316","text":"<ul> <li>Distributed Inference\uff1a\u591a\u673a\u591a\u5361\u63a8\u7406\u3001\u5206\u5e03\u5f0f\u62d3\u6251\u4e0e\u901a\u4fe1\u5f00\u9500\u3002</li> <li>KV Cache \u7ba1\u7406\u4e13\u9898\uff1a\u4ece\u62bd\u8c61\u63a5\u53e3\u5230 PagedAttention slot \u5206\u914d\u4e0e\u663e\u5b58\u788e\u7247\u6cbb\u7406\u3002</li> <li>\uff08\u9884\u7559\uff09Speculative decoding / Chunked prefill / Cascade inference / Prefix caching \u7b49\u4f18\u5316\u53ef\u4ee5\u5728\u8fd9\u91cc\u7ee7\u7eed\u62c6\u5206\u6210\u5355\u72ec\u6587\u4ef6\u540e\u6302\u94fe\u63a5\u3002</li> </ul>"},{"location":"notes/systems/vllm/kv-cache/","title":"vLLM KV Cache \u7ba1\u7406","text":"<ul> <li>PagedAttention slot \u5206\u914d\u7b56\u7565</li> <li>Chunk pin/unpin \u65f6\u5e8f</li> <li>\u4e0e GPU \u663e\u5b58\u788e\u7247\u7ba1\u7406\u7684\u8054\u52a8</li> </ul>"},{"location":"notes/systems/vllm/%E5%91%A8%E8%BE%B9%26%E4%BC%98%E5%8C%96/Distributed%20Inference/","title":"Distributed Inference","text":"<ul> <li>Why distributed inference?</li> <li>Typed of distributed inference: TP / EP / PP</li> <li>PD Disaggregation</li> </ul>"},{"location":"notes/systems/vllm/%E5%91%A8%E8%BE%B9%26%E4%BC%98%E5%8C%96/Distributed%20Inference/#why","title":"Why?","text":"<ol> <li>\u6a21\u578b\u5355\u5361\u653e\u4e0d\u4e0b</li> <li>\u63a8\u7406\u7684\u4e0d\u540c\u9636\u6bb5\u90fd\u80fd\u5145\u5206\u5229\u7528\u786c\u4ef6\u8d44\u6e90<ol> <li>prefil\uff1a\u8ba1\u7b97\u5bc6\u96c6\uff0cIO\u8981\u6c42\u4e0d\u9ad8</li> <li>decode\uff1a\u5185\u5b58\u5bc6\u96c6\u578b\u3002batch size \u5927\u4e86\u624d\u6548\u7387\u9ad8</li> </ol> </li> </ol>"},{"location":"notes/systems/vllm/%E5%91%A8%E8%BE%B9%26%E4%BC%98%E5%8C%96/Distributed%20Inference/#_1","title":"\u4f20\u7edf\u7684\u5206\u5e03\u5f0f\u65b9\u6cd5","text":""},{"location":"notes/systems/vllm/%E5%91%A8%E8%BE%B9%26%E4%BC%98%E5%8C%96/Distributed%20Inference/#tensor-parallel","title":"Tensor parallel","text":"<p>\u628a\u6a21\u578b\u540c\u4e00\u5c42\u7684weights\u62c6\u6210\u597d\u51e0\u4efd\uff0c\u5206\u5230\u4e0d\u540c\u7684\u786c\u4ef6\u4e0a\u5404\u81ea\u8ba1\u7b97\uff0c\u7136\u540e all-reduce \u91cd\u65b0\u6c47\u603b\u8d77\u6765\u3002 \u6a21\u578b\u7684\u6bcf\u4e00\u5c42\u4f1a\u88ab\u5207\u6210\u51e0\u5757\uff08\u6bd4\u5982\u56db\u5206\u4e4b\u4e00\u3001\u516b\u5206\u4e4b\u4e00\uff09\uff0c\u6bcf\u4e2a worker/GPU \u53ea\u6301\u6709\u81ea\u5df1\u90a3\u4e00\u7247\u53c2\u6570\uff0c\u5e76\u5bf9\u5b8c\u6574\u8f93\u5165\u505a\u81ea\u5df1\u7684\u90a3\u90e8\u5206\u8ba1\u7b97\uff1b\u7b49\u6240\u6709\u5206\u7247\u90fd\u7b97\u5b8c\u540e\uff0c\u518d\u628a\u8fd9\u4e9b\u5c40\u90e8\u7ed3\u679c\u62fc\u63a5\u8d77\u6765\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5c42\u8f93\u51fa\u3002</p> <p>vllm/distributed/parallel_state.py Text Only<pre><code>_TP: GroupCoordinator | None = None\ndef get_tp_group() -&gt; GroupCoordinator:\n    assert _TP is not None, \"tensor model parallel group is not initialized\"\n\n    return _TP\n</code></pre></p> Text Only<pre><code># message queue broadcaster is only used in tensor model parallel group\n\n_TP = init_model_parallel_group(\n    group_ranks,\n    get_world_group().local_rank,\n    backend,\n    use_message_queue_broadcaster=True,\n    group_name=\"tp\",\n)\n</code></pre>"},{"location":"notes/systems/vllm/%E5%91%A8%E8%BE%B9%26%E4%BC%98%E5%8C%96/Distributed%20Inference/#pipeline-parallel","title":"Pipeline parallel","text":"<p>\u628a\u4e0d\u540c\u5c42\u5206\u5e03\u5230\u4e0d\u540c GPU \u4e0a\u4e32\u8054\u8d77\u6765\u3002 Text Only<pre><code>class GroupCoordinator:\n    rank: int # global rank\n    ranks: list[int] # global ranks in the group\n    world_size: int # size of the group\n    # difference between `local_rank` and `rank_in_group`:\n    # if we have a group of size 4 across two nodes:\n    # Process | Node | Rank | Local Rank | Rank in Group\n    # 0 | 0 | 0 | 0 | 0\n    # 1 | 0 | 1 | 1 | 1\n    # 2 | 1 | 2 | 0 | 2\n    # 3 | 1 | 3 | 1 | 3\n    local_rank: int # local rank used to assign devices\n    rank_in_group: int # rank inside the group\n    cpu_group: ProcessGroup # group for CPU communication\n    device_group: ProcessGroup # group for device communication\n    # device communicator (if use_device_communicator=True)\n    device_communicator: DeviceCommunicatorBase | None\n    mq_broadcaster: Any | None # shared memory broadcaster\n</code></pre></p> <p>\u6bd4\u5982 TP=2, PP=4, \u5219rank\u4e3a0-7 ranks\uff1aTP\u7684\uff0c\u6bcf\u4e2aranks\u957f\u5ea6\u4e3a2\uff1bPP\u7684\uff0c\u6bcf\u4e2aranks\u957f\u5ea6\u4e3a4\u3002 local_rank\uff1a\u7ed9\u6bcf\u4e2arank\u5236\u5b9agpu\uff0c\u6307\u5b9a\u5728\u54ea\u4e00\u4e2aGPU\u4e0aallocate\u3002\uff08\u53d7CUDA_VISIBLE_DEVICES\u5f71\u54cd\uff09 \u901a\u4fe1\u6709\u4e24\u79cd\u6e20\u9053 - CPU communication\uff0c\u6162\uff0c\u4f46\u662f\u53ef\u63a7\u6027\u66f4\u597d\u3002 - \u57fa\u4e8e device \u7684\uff0c\u80fd\u5229\u7528\u4e0a\u786c\u4ef6\u7279\u6027\u3002     - NV Link\uff1aGPU\u548cGPU\u4e4b\u95f4\u7684 direct communication\u3002\u7269\u7406\u4e0a\u7684\u4e00\u4e2a\u8fde\u63a5\uff1b     - Infinity Bind: \u4e5f\u662f\u4e00\u4e2a\u786c\u4ef6\u3002Between nodes     - RDMA: Remote direct memory access. \u53ef\u4ee5\u907f\u514d\u7ecf\u8fc7 Operating System\uff0c\u4e0d\u7528\u8fc7CISCO\u3002</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Attention%20backend/","title":"Attention backend","text":"<p>vllm/v1/attention/backends</p> <p>\u6700\u6838\u5fc3\u770bvllm/v1/attention/backends/flash_attn.py</p> <p>prefill \u548c decode \u4f1a\u7528\u4e0d\u540c\u7684 flashattention kernel prefill\u7684\u4e0d\u9700\u8981\u4ecegpu\u91cc\u62ff\u4efb\u4f55data, flash_attn_varlen_func decode</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Engine/","title":"Engine","text":"<p>vllm/engine</p> <p>PS\uff1avllm/v1 \u4ee5\u5916\u7684\u90fd\u662f v0</p> <ul> <li>llm_engine.py \u771f\u6b63\u5e72\u6d3b\u7684</li> <li>async_llm_engine.py \u5957\u7684async\u58f3\uff0c\u5177\u6709\u5f02\u6b65\u6027</li> </ul> <p>debug\u7684\u65f6\u5019\u8bf7\u4f7f\u7528\u540c\u6b65\u7684 llm_engine.py</p> <p>vllm/v1/engine/llm_engine.py</p> Text Only<pre><code>class LLMEngine:\n</code></pre>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Entrypoint/","title":"Entrypoint","text":"<p>\u5e38\u89c1\u7684 Entrypoint \u6709\u4e24\u79cd - LLM vllm/entrypoints/llm.py - API Server vllm/entrypoints/openai/api_server.py</p> <p>API Server \u91cc Text Only<pre><code>def mount_metrics(app: FastAPI):\n</code></pre></p> <p>\u53d1\u9001\u7ed9 Engine</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Evictor/","title":"Evictor","text":"<p>\u7528\u4e8e prefix caching</p> <p>\u5982\u679c\u62e5\u6709\u76f8\u540c\u524d\u7f00\uff0c\u5219\u53ef\u4ee5\u590d\u7528\u3002\u7b2c\u4e8c\u4e2a\u76f4\u63a5\u7528\u7b2c\u4e00\u4e2a\u5f53\u65f6\u7b97\u597d\u7684 KV Cache</p> <p>evictor \u8d1f\u8d23\u51b3\u5b9a\u54ea\u4e9b\u7f13\u5b58\u8981\u88ab\u8e22\u51fa\u53bb\u7684\u4e1c\u897f\uff08\u903b\u8f91 / \u6a21\u5757\uff09</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/KV%20Cache%20Manager/","title":"KV Cache Manager","text":"<p>vllm/v1/core/block_pool.py</p> <p>Paged Attention</p> <p>\u5f53\u628arequest\u6253\u5305\u7684\u65f6\u5019\uff0c\u6bd4\u5982\u4e00\u4e2arequest 1GB\uff0c\u4e00\u5171\u670910GB\uff0c\u4f46\u662f\u5374\u53ea\u80fd\u62535\u4e2a\u5305\u3002\u56e0\u4e3a\u5728\u63a8\u7406\u7684\u65f6\u5019\u4f1a\u53d8\u957f\uff0c\u5185\u5b58\u7ba1\u7406\u4f1a\u5f88\u6df7\u4e71</p> <p>\u6240\u4ee5\u8fdb\u884c\u5207\u5206\uff0c\u4e5f\u5c31\u662fPaged Attention\u3002\u66f4\u597d\u5730\u7ba1\u7406\u663e\u5b58\u7a7a\u95f4</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Model_executer/","title":"Model Executor","text":"<p>model executer \u91cc \u6709\u4e00\u4e2a\u4e2a\u5c0f model runner</p> <p>\u6700\u7ecf\u5178\uff1avllm/model_executor/models/llama.py</p> <p>\u6700\u6838\u5fc3\u7684\u662f Text Only<pre><code>class LlamaDecoderLayer(nn.Module):\n    def forward():\n</code></pre></p> <p>\u6267\u884c\u7684\u662f norm + Attn + norm + MLP</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Modeling/","title":"Modeling","text":"<p>\u600e\u4e48\u628a\u5343\u5947\u767e\u602a\u7684\u6a21\u578b\uff0c\u5199\u6210 vLLM \u80fd\u8bfb\u61c2\u5e76\u80fd\u4f18\u5316\u7684\u6807\u51c6\u5f62\u5f0f contribution \u673a\u4f1a\u975e\u5e38\u591a</p> <p>\u5c31\u662f model_executer \u91cc\u9762\u7684 \u4e00\u4e2a\u4e2arunner</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Scheduler/","title":"Scheduler","text":"<p>vllm/v1/core/sched/scheduler.py</p> <p>core\u6587\u4ef6\u5939\u53ef\u4ee5\u7406\u89e3\u4e3a\u5b9e\u73b0 vllm paper \u7684\u5730\u65b9</p> <p>\u7ecf\u8fc7\u4e00\u6b21 inference \u7684\u8fc7\u7a0b\u53eb\u505a\u4e00\u4e2a step \uff08\u751f\u6210\u4e00\u4e2a token\uff09</p> <p>Scheduler\uff1a\u6bcf\u4e2ainference\u653e\u54ea\u4e2arequest</p> <p>\u6240\u6709request\u6253\u5305\u6210\u4e00\u4e2a\u5927\u5305\uff0c\u4e00\u8d77\u8dd1(continuous batching)</p>"},{"location":"notes/systems/vllm/%E6%A8%A1%E5%9D%97/Worker/","title":"Worker","text":"<p>vllm/v1/worker</p> <p>\u91cc\u9762\u6709\u5404\u79cd hardware \u9002\u914d \u786c\u4ef6\u8f6f\u4ef6\u7ed3\u5408\u7684\u4ea4\u9519\u70b9</p> <p>\u6838\u5fc3\uff1a vllm/v1/worker/worker_base.py \u62bd\u8c61</p> <p>vllm/v1/worker/gpu_worker.py Text Only<pre><code>class Worker(WorkerBase):\n</code></pre></p> <p>worker \u521d\u59cb\u5316\u4e00\u7cfb\u5217\u53d8\u91cf\u548c\u73af\u5883\uff0c\u7ed9 model_executer</p>"},{"location":"research/","title":"Research","text":"<p>\u9884\u7559\u4e13\u680f\uff0c\u7528\u4e8e\u8bb0\u5f55\u6df1\u5165\u7684\u7814\u7a76\u4e13\u9898\u3001\u5b9e\u9a8c\u65e5\u5fd7\u4e0e\u8bba\u6587\u8349\u7a3f\u3002</p>"},{"location":"research/#angel-lab","title":"ANGEL Lab","text":"<ul> <li>\u5468\u62a5\uff1a\u533b\u5b66\u8bca\u7597\u6307\u5357\u6570\u636e\u6e90\u68b3\u7406\uff082025-12-08 ~ 2025-12-14\uff09</li> </ul>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/","title":"\u5468\u62a5\uff1a\u533b\u5b66\u8bca\u7597\u6307\u5357\u6570\u636e\u6e90\u68b3\u7406\uff082025-12-08 ~ 2025-12-14\uff09","text":"<p># \u533b\u5b66\u8bca\u7597\u6307\u5357</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#gemini-sources","title":"\u4e00\u3001Gemini \u5217\u7684sources","text":"<p>\u5bf9\u4e8e\u6784\u5efa\u5927\u89c4\u6a21\u3001\u81ea\u52a8\u5316\u7684\u533b\u7597\u77e5\u8bc6\u5e93\uff08Knowledge Base\uff09\uff0c\u6570\u636e\u6e90\u7684\u9009\u62e9\u81f3\u5173\u91cd\u8981\u3002\u4f60\u9700\u8981\u7684\u662f\u90a3\u4e9b\u683c\u5f0f\u89c4\u8303\u3001\u66f4\u65b0\u53ca\u65f6\u3001\u4e14\u5c3d\u91cf\u514d\u8d39\u516c\u5f00\uff08Open Access\uff09\u7684\u6307\u5357\u3002</p> <p>\u4ee5\u4e0b\u662f\u56fd\u5916\u6700\u6743\u5a01\u3001\u4e14\u6700\u9002\u5408\u7528\u4e8e\u6784\u5efa NLP/LLM \u77e5\u8bc6\u5e93\u7684\u533b\u7597\u6307\u5357\u6765\u6e90\u6e05\u5355\uff1a</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#nlp","title":"\u7b2c\u4e00\u68af\u961f\uff1a\u7ed3\u6784\u6700\u6e05\u6670\u3001\u6700\u9002\u5408 NLP \u63d0\u53d6\uff08\u5f3a\u70c8\u63a8\u8350\uff09","text":"<p>\u8fd9\u4e9b\u673a\u6784\u7684\u6307\u5357\u901a\u5e38\u5305\u542b\u660e\u786e\u7684\u201c\u6d41\u7a0b\u56fe\u201d\u3001\u201c\u63a8\u8350\u7b49\u7ea7\u201d\u548c\u201c\u51b3\u7b56\u6811\u201d\uff0c\u975e\u5e38\u9002\u5408\u4f60\u7684 Text2DT \u6216 Text2KB \u4efb\u52a1\u3002</p> <ol> <li> <p>NICE Guidelines (\u82f1\u56fd\u56fd\u5bb6\u536b\u751f\u4e0e\u4e34\u5e8a\u4f18\u5316\u7814\u7a76\u6240)</p> <ul> <li>\u5730\u4f4d\uff1a \u5168\u7403\u516c\u8ba4\u7684\u6307\u5357\u5236\u5b9a\u201c\u91d1\u6807\u51c6\u201d\uff0c\u7ed3\u6784\u5316\u7a0b\u5ea6\u6700\u9ad8\u3002</li> <li>\u7279\u70b9\uff1a \u5b83\u4eec\u4e0d\u4ec5\u6709 PDF\uff0c\u7f51\u9875\u7248\u8fd8\u63d0\u4f9b\u4e86\u540d\u4e3a \"NICE Pathways\" \u7684\u4ea4\u4e92\u5f0f\u6d41\u7a0b\u56fe\uff08\u8fd9\u7b80\u76f4\u662f\u6784\u5efa\u77e5\u8bc6\u5e93\u7684\u5929\u7136\u6570\u636e\u6e90\uff09\u3002\u5185\u5bb9\u8986\u76d6\u5168\u79d1\u3002</li> <li>\u4e0b\u8f7d/\u8bbf\u95ee\uff1a \u5b8c\u5168\u514d\u8d39\u3002</li> <li>\u7f51\u5740\uff1a www.nice.org.uk/guidance</li> <li>\u5bf9\u4f60\u7684\u4ef7\u503c\uff1a \u5b83\u662f\u76ee\u524d\u505a Clinical Reasoning \u8bc4\u6d4b\u7684\u6700\u4f73\u6570\u636e\u6e90\uff0c\u56e0\u4e3a\u5b83\u7684\u903b\u8f91\u6781\u5176\u4e25\u5bc6\u3002</li> </ul> </li> <li> <p>WHO Guidelines (\u4e16\u754c\u536b\u751f\u7ec4\u7ec7)</p> <ul> <li>\u5730\u4f4d\uff1a \u5168\u7403\u536b\u751f\u6807\u51c6\u3002</li> <li>\u7279\u70b9\uff1a \u591a\u8bed\u8a00\u7248\u672c\uff08\u8fd9\u662f\u4f60\u9879\u76ee\u7684\u6838\u5fc3\u9700\u6c42\uff09\u3002\u5f88\u591a\u6307\u5357\u540c\u65f6\u63d0\u4f9b\u4e2d\u6587\u7248\u548c\u82f1\u6587\u7248\uff0c\u975e\u5e38\u9002\u5408\u505a\u4e2d\u82f1\u5bf9\u9f50\uff08Alignment\uff09\u8bad\u7ec3\u3002\u91cd\u70b9\u5173\u6ce8\u4f20\u67d3\u75c5\u3001\u6bcd\u5a74\u5065\u5eb7\u3001\u521d\u7ea7\u536b\u751f\u4fdd\u5065\u3002</li> <li>\u4e0b\u8f7d/\u8bbf\u95ee\uff1a IRIS \u6570\u636e\u5e93\u5b8c\u5168\u514d\u8d39 PDF \u4e0b\u8f7d\u3002</li> <li>\u7f51\u5740\uff1a www.who.int/publications/i</li> <li>\u5bf9\u4f60\u7684\u4ef7\u503c\uff1a \u89e3\u51b3\u4f60\u201c\u591a\u8bed\u8a00\u201d\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002</li> </ul> </li> <li> <p>NCCN Guidelines (\u7f8e\u56fd\u56fd\u5bb6\u7efc\u5408\u764c\u75c7\u7f51\u7edc)</p> <ul> <li>\u5730\u4f4d\uff1a \u80bf\u7624\u5b66\u9886\u57df\u7684\u201c\u5723\u7ecf\u201d\u3002</li> <li>\u7279\u70b9\uff1a \u7531\u5927\u91cf\u7684\u7b97\u6cd5\u6d41\u7a0b\u56fe\uff08Algorithms\uff09\u7ec4\u6210\u3002\u51e0\u4e4e\u6bcf\u4e00\u9875\u90fd\u662f\u51b3\u7b56\u6811\uff0c\u975e\u5e38\u5bb9\u6613\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u3002</li> <li>\u4e0b\u8f7d/\u8bbf\u95ee\uff1a \u514d\u8d39\uff0c\u4f46\u9700\u8981\u6ce8\u518c\u4e00\u4e2a\u8d26\u53f7\uff08Free Registration\uff09\u3002</li> <li>\u7f51\u5740\uff1a www.nccn.org/guidelines</li> <li>\u5bf9\u4f60\u7684\u4ef7\u503c\uff1a \u7ade\u54c1 MedGUIDE \u7528\u7684\u5c31\u662f\u8fd9\u4e2a\u3002\u4f60\u53ef\u4ee5\u722c\u53d6\u4e0b\u6765\u505a\u66f4\u5927\u89c4\u6a21\u7684\u8986\u76d6\u3002</li> </ul> </li> </ol>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_1","title":"\u7b2c\u4e8c\u68af\u961f\uff1a\u4e13\u4e1a\u5b66\u79d1\u6743\u5a01\uff08\u542b\u91d1\u91cf\u6781\u9ad8\uff09","text":"<p>\u8fd9\u4e9b\u901a\u5e38\u662f\u5404\u4e13\u79d1\u7684\u9876\u7ea7\u5b66\u4f1a\uff0c\u5b83\u4eec\u7684\u6307\u5357\u901a\u5e38\u53d1\u8868\u5728\u9876\u7ea7\u671f\u520a\uff08\u5982 JACC, Circulation, Diabetes Care\uff09\u4e0a\uff0c\u901a\u5e38\u662f\u514d\u8d39\u5f00\u653e\u83b7\u53d6\uff08Open Access\uff09\u7684 PDF\u3002</p> <ol> <li> <p>ESC (\u6b27\u6d32\u5fc3\u810f\u75c5\u5b66\u4f1a)</p> <ul> <li>\u9886\u57df\uff1a \u5fc3\u8840\u7ba1\uff08\u9ad8\u8840\u538b\u3001\u51a0\u5fc3\u75c5\u3001\u5fc3\u8870\uff09\u3002</li> <li>\u7279\u70b9\uff1a \u6781\u5176\u8be6\u5c3d\uff0c\u6bcf\u4e2a\u6307\u5357\u90fd\u5305\u542b\u5927\u91cf\u7684\u603b\u7ed3\u8868\u683c\uff08Summary Cards\uff09\u548c\u6d41\u7a0b\u56fe\u3002</li> <li>\u4e0b\u8f7d/\u8bbf\u95ee\uff1a \u5b98\u7f51\u514d\u8d39\u4e0b\u8f7d PDF\u3002</li> <li>\u7f51\u5740\uff1a www.escardio.org/Guidelines</li> </ul> </li> <li> <p>AHA / ACC (\u7f8e\u56fd\u5fc3\u810f\u534f\u4f1a / \u7f8e\u56fd\u5fc3\u810f\u75c5\u5b66\u4f1a)</p> <ul> <li>\u9886\u57df\uff1a \u5fc3\u8840\u7ba1\u3002\u4e0e ESC \u5e76\u5217\u3002</li> <li>\u7279\u70b9\uff1a \u6587\u672c\u91cf\u5f88\u5927\uff0c\u903b\u8f91\u4e25\u5bc6\u3002\u901a\u5e38\u53d1\u5e03\u5728 Circulation \u6216 JACC \u671f\u520a\u4e0a\u3002</li> <li>\u4e0b\u8f7d/\u8bbf\u95ee\uff1a \u5b98\u7f51\u6216\u671f\u520a\u7f51\u7ad9\u514d\u8d39\u83b7\u53d6\u3002</li> <li>\u7f51\u5740\uff1a www.ahajournals.org/journal/circ-guidelines</li> </ul> </li> <li> <p>ADA (\u7f8e\u56fd\u7cd6\u5c3f\u75c5\u534f\u4f1a)</p> <ul> <li>\u9886\u57df\uff1a \u5185\u5206\u6ccc\uff08\u4e3b\u8981\u662f\u7cd6\u5c3f\u75c5\uff09\u3002</li> <li>\u7279\u70b9\uff1a \u6bcf\u5e74\u66f4\u65b0\u4e00\u6b21 \"Standards of Care in Diabetes\"\u3002\u8fd9\u662f\u4e00\u672c\u5f88\u539a\u7684\u4e66\uff0c\u4f46\u7ed3\u6784\u975e\u5e38\u6807\u51c6\u5316\uff0c\u6709\u5f88\u591a\u8868\u683c\u3002</li> <li>\u4e0b\u8f7d/\u8bbf\u95ee\uff1a \u6bcf\u5e74\u4e00\u6708\u7684 Diabetes Care \u671f\u520a\u514d\u8d39\u53d1\u5e03\u3002</li> <li>\u7f51\u5740\uff1a professional.diabetes.org/content-page/practice-guidelines-resources</li> </ul> </li> <li> <p>IDSA (\u7f8e\u56fd\u4f20\u67d3\u75c5\u5b66\u4f1a)</p> <ul> <li>\u9886\u57df\uff1a \u611f\u67d3\u75c5\uff08\u80ba\u708e\u3001\u6297\u751f\u7d20\u4f7f\u7528\u3001COVID-19\uff09\u3002</li> <li>\u7279\u70b9\uff1a \u9488\u5bf9\u7279\u5b9a\u75c5\u539f\u4f53\u548c\u4e34\u5e8a\u573a\u666f\u7684\u63a8\u8350\u975e\u5e38\u5177\u4f53\u3002</li> <li>\u4e0b\u8f7d/\u8bbf\u95ee\uff1a \u5b98\u7f51\u514d\u8d39\u3002</li> <li>\u7f51\u5740\uff1a www.idsociety.org/practice-guidelines</li> </ul> </li> </ol>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_2","title":"\u7b2c\u4e09\u68af\u961f\uff1a\u7efc\u5408\u6027\u6307\u5357\u5e93\uff08\u9002\u5408\u6279\u91cf\u722c\u53d6\uff09","text":"<p>\u5982\u679c\u4f60\u4e0d\u60f3\u4e00\u4e2a\u4e00\u4e2a\u5b66\u4f1a\u53bb\u627e\uff0c\u53ef\u4ee5\u53bb\u8fd9\u4e9b\u805a\u5408\u5e73\u53f0\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u6570\u636e\u6e05\u6d17\u7684\u96be\u5ea6\u3002</p> <ol> <li> <p>CMA Infobase (\u52a0\u62ff\u5927\u533b\u5b66\u4f1a\u4e34\u5e8a\u6307\u5357\u5e93)</p> <ul> <li>\u7279\u70b9\uff1a \u8fd9\u662f\u4e00\u4e2a Repository\uff08\u4ed3\u5e93\uff09\uff0c\u6c47\u96c6\u4e86\u52a0\u62ff\u5927\u5404\u5b66\u4f1a\u7684\u6307\u5357\u3002\u652f\u6301\u6309\u79d1\u5ba4\u641c\u7d22\u3002</li> <li>\u7f51\u5740\uff1a joule.cma.ca/en/evidence/clinical-practice-guidelines</li> </ul> </li> <li> <p>ECRI Guidelines Trust (\u524d\u8eab\u662f National Guideline Clearinghouse)</p> <ul> <li>\u6ce8\u610f\uff1a \u4ee5\u524d\u7f8e\u56fd\u653f\u5e9c\u7ef4\u62a4\u7684 NGC \u5df2\u7ecf\u5173\u505c\uff0c\u73b0\u5728\u7531 ECRI \u63a5\u624b\u3002</li> <li>\u95e8\u69db\uff1a \u53ef\u80fd\u9700\u8981\u6ce8\u518c\uff0c\u90e8\u5206\u5185\u5bb9\u53ef\u80fd\u6536\u8d39\u3002\u53ef\u4ee5\u4f5c\u4e3a\u5907\u9009\u3002</li> <li>\u7f51\u5740\uff1a guidelines.ecri.org</li> </ul> </li> <li> <p>MAGICapp</p> <ul> <li>\u7279\u70b9\uff1a \u8fd9\u662f\u4e00\u4e2a\u6570\u5b57\u5316\u6307\u5357\u53d1\u5e03\u5e73\u53f0\u3002\u5f88\u591a\u56fd\u9645\u7ec4\u7ec7\u5728\u8fd9\u91cc\u53d1\u5e03\u6307\u5357\u3002</li> <li>\u6838\u5fc3\u4f18\u52bf\uff1a \u5b83\u7684\u6570\u636e\u672c\u8eab\u5c31\u662f\u7ed3\u6784\u5316\u7684\uff08Digitally structured guidelines\uff09\uff0c\u800c\u4e0d\u662f\u6b7b\u677f\u7684 PDF\u3002\u5982\u679c\u4f60\u80fd\u5199\u722c\u866b\u89e3\u6790\u5b83\u7684\u683c\u5f0f\uff0c\u80fd\u7701\u53bb\u5927\u91cf NLP \u63d0\u53d6\u7684\u5de5\u4f5c\u3002</li> <li>\u7f51\u5740\uff1a app.magicapp.org</li> </ul> </li> </ol> <p>\u4e3a\u4e86\u6784\u5efa\u60a8\u7684 Multilingual KB\uff0c\u6211\u5efa\u8bae\u91c7\u53d6\u4ee5\u4e0b\u7b56\u7565\u7ec4\u5408\uff1a</p> <ol> <li> <p>\u591a\u8bed\u8a00\u5bf9\u9f50\u6570\u636e\u96c6\uff08\u6838\u5fc3\u4eae\u70b9\uff09\uff1a</p> <ul> <li>\u4e0b\u8f7d WHO \u7684\u4e2d\u6587\u7248\u548c\u82f1\u6587\u7248\u6307\u5357\u3002</li> <li>\u4e0b\u8f7d ESC (\u6b27\u6d32) \u7684\u6307\u5357\uff08\u82f1\u6587\uff09\u548c \u4e2d\u534e\u533b\u5b66\u4f1a\u5fc3\u8840\u7ba1\u75c5\u5b66\u5206\u4f1a \u7684\u6307\u5357\uff08\u4e2d\u6587\uff09\u3002</li> <li>\u4efb\u52a1\uff1a \u6784\u5efa\u4e00\u4e2a\u201c\u4e2d\u897f\u533b\u8bca\u7597\u903b\u8f91\u5bf9\u6bd4\u201d\u5b50\u96c6\u3002</li> </ul> </li> <li> <p>\u6d41\u7a0b\u56fe\u63d0\u53d6\u6570\u636e\u96c6\uff08\u6280\u672f\u9a8c\u8bc1\uff09\uff1a</p> <ul> <li>\u6279\u91cf\u4e0b\u8f7d NCCN \u548c NICE \u7684\u6307\u5357\u3002</li> <li>\u5229\u7528\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08\u5982 GPT-4o \u6216 Qwen-VL\uff09\u63d0\u53d6\u5176\u4e2d\u7684\u6d41\u7a0b\u56fe\uff0c\u8f6c\u5316\u4e3a JSON/Mermaid \u4ee3\u7801\u3002</li> </ul> </li> <li> <p>\u6587\u672c\u8f6c\u903b\u8f91\u6570\u636e\u96c6\uff08\u5927\u89c4\u6a21\u6269\u5145\uff09\uff1a</p> <ul> <li>\u4f7f\u7528 AHA \u548c ADA \u7684\u7eaf\u6587\u672c\u6307\u5357\uff0c\u8bad\u7ec3\u6a21\u578b\u4ece\u6587\u672c\u4e2d\u63d0\u53d6 \"If-Then\" \u89c4\u5219\u3002</li> </ul> </li> </ol>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_3","title":"\u7ed9\u7814\u7a76\u5458\u7684\u201c\u64cd\u4f5c\u5efa\u8bae\u201d","text":""},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_4","title":"\u4e8c\u3001\u6b63\u5728\u8fdb\u884c\u4e2d\u6307\u5357\u6574\u7406","text":""},{"location":"research/ANGEL-lab/week_reports/1208-1214/#nice","title":"NICE \u2705","text":"<p>\u82f1\u56fd\u4e0e\u5a01\u5c14\u58eb</p> <p>\u6307\u5357\u5217\u8868\uff1ahttps://www.nice.org.uk/guidance/published?sp=on</p> <p>url\u4f8b\u5b50\uff1ahttps://www.nice.org.uk/guidance/ta1116</p> <p>\u4ee3\u7801\u5df2\u7ecf\u51c6\u5907\u597d</p> <p>\u67092522\u4e2apdf\uff0c2007\u4e2aGuidance\uff0c318\u4e2aNICE advice\uff0c197\u4e2aQuality Standard</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#who-iris","title":"WHO IRIS","text":"<p>\u9700\u8981\u7ee7\u7eed\u8fc7\u6ee4</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#nccn","title":"NCCN","text":"<p>\u7f8e\u56fd\u764c\u75c7\u6570\u636e\u96c6 \u9700\u8981\u6ce8\u518c\u8d26\u53f7</p> <p>https://www.nccn.org/business-policy/business/firewall-policy</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_5","title":"\u4e2d\u56fd\u536b\u5065\u59d4","text":"<p>https://www.nhc.gov.cn/wjw/s9491/wsbz.shtml</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#pmc","title":"PMC","text":"<p>https://pmc.ncbi.nlm.nih.gov/tools/openftlist/</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#mimic-iv","title":"MIMIC-IV","text":"<p>https://physionet.org/content/mimiciv/3.1/</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#caca","title":"CACA \u4e2d\u56fd\u80bf\u7624\u6574\u5408\u8bca\u6cbb\u6307\u5357","text":"<p>https://cacaguidelines.cacakp.com/</p> <p>\u53ef\u4ee5\u76f4\u63a5\u4e0b\u8f7d</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#csco","title":"CSCO \u4e2d\u56fd\u4e34\u5e8a\u80bf\u7624\u5b66\u4f1a \u274c","text":"<p>https://www.csco.org.cn/cn/index.aspx</p> <p>\u9700\u8981\u4ed8\u8d39\u8ba2\u8d2d</p> <p>\u4f46\u662f\u6216\u8bb8\u53ef\u4ee5\u5728\u5176\u4ed6\u5730\u65b9\u627e\u5230\uff0c\u6bd4\u5982https://scsfybjlib.yuntsg.com/official/html/380/newsDetails.html?id=1155&amp;typeId=1</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_6","title":"\u4e0b\u8f7d\u540e\u7eed","text":"<p>\u8fc7\u6ee4\u6807\u9898\uff1f</p> <p>pdf\u5220\u9664\u65e0\u7528\u9875\u9762</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_7","title":"\u4e09\u3001\u8bba\u6587\u9605\u8bfb","text":""},{"location":"research/ANGEL-lab/week_reports/1208-1214/#kggen","title":"KGGen","text":"<p>https://github.com/stair-lab/kg-gen</p> <p>\u9996\u5148\u4f7f\u7528LLM\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u5b9e\u4f53\u548c\u5173\u7cfb\u4e09\u5143\u7ec4\uff0c\u7136\u540e\u901a\u8fc7\u805a\u5408\u53bb\u91cd\uff0c\u6700\u540e\u91c7\u7528\u6df7\u5408LLM\u4e0e\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u65b9\u6cd5\u7684\u8fed\u4ee3\u805a\u7c7b\u7b97\u6cd5\u8fdb\u884c\u5b9e\u4f53\u548c\u8fb9\u7684\u6d88\u6b67\u3002</p> <p>\u7814\u7a76\u56e2\u961f\u540c\u65f6\u53d1\u5e03\u4e86\u9996\u4e2a\u8bc4\u4f30\u57fa\u51c6MINE\uff0c\u5305\u542bMINE-1\u548cMINE-2\u4e24\u4e2a\u4efb\u52a1\uff0c\u5206\u522b\u7528\u4e8e\u8bc4\u4f30\u77ed\u6587\u672c\u4fe1\u606f\u4fdd\u7559\u80fd\u529b\u548c\u5927\u89c4\u6a21\u6587\u672c\u7684RAG\u6027\u80fd\u3002</p> <p>\u91cd\u70b9\uff1a  - plain text to knowledge graph\uff0c \u610f\u5473\u7740\u9700\u8981\u81ea\u5df1\u89e3\u6790  - \u9700\u8981\u5927\u91cfLLM\u8c03\u7528</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#medguide","title":"MedGUIDE","text":"<p>https://arxiv.org/pdf/2505.11613</p> <p>\u4f7f\u7528 NCNN \u7f8e\u56fd\u764c\u75c7\u8bca\u65ad\u6307\u5357\uff0c\u5bf917\u79cd\u764c\u75c7\u5efa\u7acb55\u68f5\u8bca\u65ad\u51b3\u7b56\u6811\uff0c\u7136\u540e\u4f9d\u636e\u8fd9\u4e9b\u6811\uff0c\u4f7f\u7528\u4e13\u5bb6\u5956\u52b1\u548cLLM\u8bc4\u5206\uff0c\u7f16\u5199\u5355\u9009\u9898\u3002</p> <p>\u4f7f\u7528\u51b3\u7b56\u6811\u8fdb\u884c\u5fae\u8c03\u540e\uff0c\u6548\u679c\u63d0\u5347\u3002</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#reason-med","title":"Reason Med \u963f\u91cc\u8fbe\u6469\u9662","text":"<p>https://github.com/alibaba-damo-academy/ReasonMed</p> <p>\u57fa\u4e8e\u4f20\u7edf\u9009\u62e9\u9898\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u751f\u6210\u4e0e\u4e09\u7ea7\u9a8c\u8bc1\u673a\u5236\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u751f\u6210\u5b8c\u6574\u601d\u7ef4\u94fe\u3002370k\u6761\u3002</p> <ul> <li>\u6570\u636e\u96c6\u89c4\u6a21\u7a81\u7834\uff1aReasonMed\u5305\u542b37\u4e07\u6761\u533b\u5b66\u95ee\u7b54\u6837\u672c\uff0c\u662f\u73b0\u6709\u6570\u636e\u96c6\u89c4\u6a21\u768410\u500d\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210175\u4e07\u6761\u63a8\u7406\u8def\u5f84\u3002</li> <li>\u4e09\u7ea7\u9a8c\u8bc1\u673a\u5236\uff1a\u6839\u636e\u9519\u8bef\u6570\u91cf\u5206\u7ea7\u5904\u7406\uff0c\u6613\u7ea7\u4fdd\u7559Top2\u8def\u5f84\uff0c\u4e2d\u7ea7\u4fee\u6b63\u9519\u8bef\u6b65\u9aa4\uff0c\u96be\u7ea7\u91cd\u65b0\u751f\u6210\uff0c\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002</li> <li>\u6df7\u5408\u8bad\u7ec3\u7b56\u7565\uff1a\u7ed3\u5408CoT\u8be6\u7ec6\u63a8\u7406\u4e0eResponse\u6458\u8981\u8bad\u7ec3\uff0c\u4f7fReasonMed-7B\u5728PubMedQA\u8d85\u8d8aLLaMA3.1-70B+4.6%\uff0c\u4e14\u8bad\u7ec3\u6210\u672c\u4f4e\u4e8e\u7eafCoT\u8bad\u7ec3\u3002</li> <li>\u6a21\u578b\u6269\u5c55\u6027\uff1aReasonMed-14B\u57289\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aQwen2.5-32B\uff0c\u63a5\u8fd1LLaMA3.1-70B\u8868\u73b0\uff0c\u8bc1\u660e\u6570\u636e\u8d28\u91cf\u4f18\u4e8e\u53c2\u6570\u89c4\u6a21\u3002</li> </ul> <p>\u4f7f\u7528\u7684\u751f\u6210\u6a21\u578b\uff1aQwen2.5-72B, HuatuoGPT-o1-70B, DeepSeek-R1-Distill-Llama-70B</p> <p>\u4e0d\u540c\u91c7\u6837temperature\u751f\u6210CoT\u3002</p> <ul> <li>Verifier: not only checks whether the answer iscorrect or incorrect, but also evaluates whether thekey clinical factors have been accurately identified</li> <li>Response Summarizer</li> <li>Quality Ranker: Qwen, directly outputting the two best paths by theirCoT names</li> <li>Error Refiner: \u4e2d\u7b49\u96be\u5ea6\u4f7f\u7528\u3002 prioritizes issues surfaced by the Verifier</li> <li>Score Evaluator: gpt-4o. \u6253\u52060-10.</li> </ul> <p>\u5fae\u8c03\u5b9e\u9a8c\uff1a\u7eafCoT\uff0c\u7eafSummarization\uff0c\u7ec4\u5408\u3002\uff08\u56fa\u5b9a6\u6761CoT\uff09</p> <p>\u4f7f\u7528Score Evaluator\u8fdb\u884c\u8bc4\u5206\u3002</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#training-and-evaluation-of-guideline-based-medical-reasoning-in-llms-12","title":"Training and Evaluation of Guideline-Based Medical Reasoning in LLMs  \u6700\u65b0 12\u6708 \u53d1\u5e03","text":"<p>https://arxiv.org/abs/2512.03838</p> <p>\u6784\u5efa\u5305\u542b\u6f14\u7ece\u63a8\u7406\u548c\u5f52\u7eb3\u63a8\u7406\u7684\u533b\u5b66\u89c4\u5219\u8bad\u7ec3\u96c6\uff0c\u63d0\u51fa\u63a8\u5bfc\u6b63\u786e\u6027\u548c\u6570\u503c\u6b63\u786e\u6027\u7684\u53cc\u7ef4\u5ea6\u8bc4\u4f30\u4f53\u7cfb\u3002</p> <p>Sepsis-3\u5b9a\u4e49\uff1a2016\u5e74\u56fd\u9645\u8113\u6bd2\u75c7\u5b9a\u4e49\u4f1a\u8bae\u63d0\u51fa\u7684\u8bca\u65ad\u6807\u51c6\uff0c\u901a\u8fc7SOFA\u8bc4\u5206\u53d8\u5316\u22652\u5206\u7ed3\u5408\u611f\u67d3\u8bc1\u636e\u5224\u5b9a\u8113\u6bd2\u75c7\uff0c\u5305\u542b\u5668\u5b98\u529f\u80fd\u969c\u788d\u7684\u91cf\u5316\u8bc4\u4f30\u4f53\u7cfb\u3002 \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff1a\u901a\u8fc7\u5386\u53f2\u4e34\u5e8a\u6570\u636e\u9884\u6d4b\u672a\u676524\u5c0f\u65f6\u6307\u6807\u53d8\u5316\u7684\u6280\u672f\uff0c\u7528\u4e8e\u8ba1\u7b97\u672a\u6765SOFA\u8bc4\u5206\uff0c\u662f\u8113\u6bd2\u75c7\u65e9\u671f\u9884\u6d4b\u7684\u5173\u952e\u73af\u8282\u3002</p> <ul> <li>deductive: \u57fa\u4e8e\u533b\u5b66\u5171\u8bc6\u7ed9\u51fa\u7684\u786e\u5b9a\u6027 if\u2013then \u89c4\u5219\u3002\u5728\u524d\u63d0\u6761\u4ef6\u6210\u7acb\u7684\u60c5\u51b5\u4e0b\uff0c\u7ed3\u8bba\u5fc5\u7136\u6210\u7acb\u3002</li> <li>inductive: \u57fa\u4e8e\u4e34\u5e8a\u7edf\u8ba1\u8bc1\u636e\u7684\u6982\u7387\u6027 if\u2013then \u89c4\u5219\u3002\u524d\u63d0\u6761\u4ef6\u53ea\u4f1a\u63d0\u9ad8\u7ed3\u8bba\u6210\u7acb\u7684\u53ef\u80fd\u6027\uff0c\u800c\u975e\u4fdd\u8bc1\u3002\u8f93\u51fa\u7684\u662f\u6982\u7387\u3002</li> </ul> <p>For each area, verbalization of consensus rules can be done automatically by using templates (which can themselves be generated automatically by using LLMs) that describe each step of an application of a consensus rule system to patient data. \u4f7f\u7528LLM\uff0c\u628a\u6307\u5357\u91cd\u5199\u6210\u6587\u5b57</p> <p>Our results show that small fine-tuned models (LLaMA 8B parameters) outperform one-shot learning of considerably larger LLMs (LLaMA 70B parameters) that are given the explicit definition in the prompt, and LLMs that are trained on medical texts including the original consensus definitions (Me-LLaMA 8B parameters) under all evaluation metrics.</p> <p>\u5728\u6f14\u7ece\u5c42\u9762\uff0cSepsis-3 \u901a\u8fc7\u4e00\u7ec4\u786e\u5b9a\u6027\u7684 if\u2013then \u89c4\u5219\uff0c\u5c06 24 \u5c0f\u65f6\u5185\u4e34\u5e8a\u53d8\u91cf\u7684\u6781\u503c\u6620\u5c04\u4e3a\u516d\u4e2a\u5668\u5b98\u7cfb\u7edf\u7684 SOFA \u5b50\u8bc4\u5206\uff0c\u5e76\u6c47\u603b\u5f97\u5230\u603b SOFA \u5206\u6570\uff1b\u8fdb\u4e00\u6b65\u901a\u8fc7\u5224\u65ad\u672a\u6765 SOFA \u5206\u6570\u76f8\u8f83\u5f53\u524d\u662f\u5426\u589e\u52a0\u81f3\u5c11 2 \u5206\uff0c\u5e76\u7ed3\u5408\u201c\u7591\u4f3c\u611f\u67d3\u201d\u6307\u793a\u53d8\u91cf\uff0c\u786e\u5b9a\u6700\u7ec8\u7684 Sepsis \u6807\u7b7e\u3002 \u5728\u5f52\u7eb3\u5c42\u9762\uff0c\u4e3a\u4e86\u5b9e\u73b0\u65e9\u671f\u9884\u6d4b\uff0c\u9700\u8981\u5bf9\u672a\u6765 24 \u5c0f\u65f6\u7684\u4e34\u5e8a\u53d8\u91cf\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\uff0c\u518d\u5c06\u9884\u6d4b\u503c\u4ee3\u5165\u540c\u4e00\u5957\u6f14\u7ece\u89c4\u5219\u4e2d\u5b8c\u6210\u63a8\u7406\u3002\u6574\u4f53\u6d41\u7a0b\u4f53\u73b0\u4e86\uff1a\u786e\u5b9a\u6027\u7684\u533b\u5b66\u5171\u8bc6\u89c4\u5219\uff08\u6f14\u7ece\uff09\u4e0e\u4e0d\u786e\u5b9a\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08\u5f52\u7eb3\uff09\u76f8\u7ec4\u5408\uff0c\u5176\u4e2d\u6a21\u578b\u63a8\u7406\u7684\u4e3b\u8981\u74f6\u9888\u5e76\u4e0d\u5728\u89c4\u5219\u5b66\u4e60\uff0c\u800c\u5728\u5bf9\u672a\u6765\u4e34\u5e8a\u53d8\u91cf\u7684\u9884\u6d4b\u80fd\u529b\u4e0a\u3002</p> <p></p> <p>Figure 2 \u5c55\u793a\u4e86\u6807\u51c6 Sepsis-3 \u63a8\u7406\u4e0e\u5f15\u5165\u533b\u5b66\u524d\u7f6e\u6761\u4ef6\u540e\u7684\u89c4\u5219\u4f8b\u5916\u63a8\u7406\u5bf9\u6bd4\u3002\u5728\u65e0\u57fa\u7840\u75be\u75c5\u65f6\uff0c\u6a21\u578b\u4e25\u683c\u6309\u7167 SOFA \u589e\u91cf\u89c4\u5219\u5224\u5b9a Sepsis\uff1b\u800c\u5728\u5b58\u5728\u6162\u6027\u80be\u75c5\u7b49\u524d\u7f6e\u6761\u4ef6\u65f6\uff0c\u76f8\u5e94\u5668\u5b98\u7684 SOFA \u5b50\u9879\u88ab\u5ffd\u7565\uff0c\u5bfc\u81f4\u603b SOFA \u4e0d\u518d\u589e\u52a0\uff0c\u4ece\u800c\u6539\u53d8\u6700\u7ec8\u8bca\u65ad\u7ed3\u679c\u3002\u8fd9\u8bf4\u660e\u6a21\u578b\u4e0d\u4ec5\u5b66\u4e60\u4e86\u5171\u8bc6\u89c4\u5219\u672c\u8eab\uff0c\u4e5f\u80fd\u5b66\u4e60\u89c4\u5219\u5728\u7279\u5b9a\u533b\u5b66\u6761\u4ef6\u4e0b\u7684\u4f8b\u5916\u3002</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#_8","title":"\u56db\u3001\u8fdb\u5ea6&amp;\u5f85\u529e","text":"<p>MIMIC-IV\u548cNICE\u5df2\u7ecf\u722c\u53d6\u5b8c\u6bd5</p> <p>KG-GEN\u6d4b\u8bd5\u5b8c\u6bd5</p> <p>\u7ee7\u7eed\u67e5\u9605\u5e76\u4e0b\u8f7d\u53ef\u4ee5\u4f7f\u7528\u7684\u533b\u5b66\u6307\u5357\u3002\u5bfb\u627e\u522b\u7684\u6709\u6ca1\u6709\u66f4\u597d\u7684\u77e5\u8bc6\u5e93\u5efa\u5e93\u65b9\u6cd5\u3002\u5bfb\u627epdf\u89e3\u6790\u6210 plain text \u7684\u6846\u67b6\u3002\u4f7f\u7528NICE\u7684\u6307\u5357\u505a\u4e00\u4e2ademo\u3002</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#gemini","title":"\u9644\u5f55\uff1aGemini\u7684\u5efa\u8bae","text":""},{"location":"research/ANGEL-lab/week_reports/1208-1214/#1-objective","title":"1. \u6838\u5fc3\u76ee\u6807 (Objective)","text":"<p>\u4e0d\u53ea\u505a\u4e00\u4e2a\u9759\u6001\u77e5\u8bc6\u5e93\uff0c\u800c\u662f\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u6307\u5357\u903b\u8f91\uff08Ground Truth\uff09\u7684\u4e34\u5e8a\u63a8\u7406\u8bc4\u6d4b\u57fa\u51c6\uff08Benchmark\uff09\u3002 \u6838\u5fc3\u903b\u8f91\uff1a<code>PDF\u6307\u5357 -&gt; \u81ea\u52a8\u5316\u63d0\u53d6\u903b\u8f91\u6811 (KB) -&gt; \u751f\u6210\u63a8\u7406\u8003\u9898 -&gt; \u8bc4\u6d4b LLM \u4f9d\u4ece\u6027</code>\u3002</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#2-the-engine","title":"2. \u9636\u6bb5\u4e00\uff1a\u81ea\u52a8\u5316\u903b\u8f91\u5e93\u6784\u5efa (The Engine)","text":"<p>\u5229\u7528 KGGen \u601d\u8def\uff0c\u4f46\u4fee\u6539\u4e3a\u201c\u903b\u8f91\u63d0\u53d6\u6a21\u5f0f\u201d\u3002</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#a","title":"A. \u6570\u636e\u6e05\u6d17\u4e0e\u89e3\u6790","text":"<ul> <li>\u5de5\u5177: \u90e8\u7f72 MinerU (Magic-PDF) \u6216 Nougat\u3002</li> <li>\u4efb\u52a1: \u5c06 NICE/WHO \u7684 PDF \u8f6c\u5316\u4e3a\u5e26\u5c42\u7ea7\u7684 Markdown\u3002</li> <li>\u91cd\u70b9: \u5fc5\u987b\u4fdd\u7559\u8868\u683c\u548c\u5d4c\u5957\u5217\u8868\uff0c\u8fd9\u662f\u903b\u8f91\u6700\u5bc6\u96c6\u7684\u5730\u65b9\u3002</li> </ul>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#b-modified-kggen","title":"B. \u903b\u8f91\u56fe\u8c31\u63d0\u53d6 (Modified KGGen)","text":"<ul> <li>Schema \u6539\u9020: \u653e\u5f03\u4f20\u7edf\u4e09\u5143\u7ec4\uff0c\u5b9a\u4e49\u201c\u51b3\u7b56\u8282\u70b9\u201d\u3002<ul> <li><code>Condition Node</code> (e.g., \"SBP &gt; 140\")</li> <li><code>Action Node</code> (e.g., \"Prescribe ACEI\")</li> <li><code>Logic Edge</code> (e.g., \"AND\", \"OR\", \"NEXT_STEP\", \"EXCEPTION\")</li> </ul> </li> <li>Prompt \u7b56\u7565: \"Extract the clinical decision tree from the text as JSON. Identify explicit IF-THEN rules and Exclusion criteria.\"</li> </ul>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#3-benchmark-the-product","title":"3. \u9636\u6bb5\u4e8c\uff1aBenchmark \u751f\u6210\u7b56\u7565 (The Product)","text":"<p>\u57fa\u4e8e\u63d0\u53d6\u51fa\u7684\u903b\u8f91\u5e93\uff0c\u53cd\u5411\u751f\u6210\u6d4b\u8bd5\u9898\u3002</p>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#1-forward-reasoning","title":"\u4efb\u52a1\u7c7b\u578b 1\uff1a\u6b63\u5411\u6f14\u7ece (Forward Reasoning)","text":"<ul> <li>\u8f93\u5165: \u6839\u636e KB \u4e2d\u7684 <code>Condition</code> \u8282\u70b9\uff0c\u4f7f\u7528 LLM \u751f\u6210\u4e00\u4e2a\u865a\u62df\u75c5\u4eba\u75c5\u4f8b\uff08Case Description\uff09\u3002</li> <li>\u95ee\u9898: \"\u6839\u636e NICE \u6307\u5357\uff0c\u8be5\u75c5\u4eba\u4e0b\u4e00\u6b65\u6700\u6070\u5f53\u7684\u5904\u7406\u662f\u4ec0\u4e48\uff1f\"</li> <li>\u91d1\u6807 (Gold Truth): KB \u4e2d\u7684 <code>Action</code> \u8282\u70b9\u3002</li> <li>\u8003\u5bdf\u70b9: \u4e25\u683c\u4f9d\u4ece\u6027\uff08Adherence\uff09\u3002</li> </ul>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#2-counterfactual-reasoning-sepsis-3","title":"\u4efb\u52a1\u7c7b\u578b 2\uff1a\u53cd\u4e8b\u5b9e\u63a8\u7406 (Counterfactual Reasoning) - Sepsis-3\u601d\u8def","text":"<ul> <li>\u8f93\u5165: \u4fee\u6539\u75c5\u4f8b\u4e2d\u7684\u67d0\u4e00\u4e2a\u5173\u952e\u53d8\u91cf\uff08\u4f8b\u5982\uff1a\u5e74\u9f84\u4ece 60 \u6539\u4e3a 85\uff0c\u6216\u589e\u52a0\u201c\u80be\u529f\u80fd\u4e0d\u5168\u201d\u75c5\u53f2\uff09\u3002</li> <li>\u95ee\u9898: \"\u5982\u679c\u8be5\u75c5\u4eba\u60a3\u6709\u6162\u6027\u80be\u75c5\uff0c\u8bca\u65ad/\u6cbb\u7597\u65b9\u6848\u6709\u4f55\u53d8\u5316\uff1f\"</li> <li>\u91d1\u6807: KB \u4e2d\u7684 <code>Exception</code> \u6216 <code>Alternative</code> \u5206\u652f\u3002</li> <li>\u8003\u5bdf\u70b9: \u5bf9\u6307\u5357\u4e2d\u201c\u4f8b\u5916\u60c5\u51b5\u201d\u548c\u201c\u7981\u5fcc\u75c7\u201d\u7684\u638c\u63e1\u3002</li> </ul>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#3-conflict-detection-","title":"\u4efb\u52a1\u7c7b\u578b 3\uff1a\u8de8\u6307\u5357\u51b2\u7a81\u68c0\u6d4b (Conflict Detection) - \u6838\u5fc3\u521b\u65b0","text":"<ul> <li>\u8f93\u5165: \u540c\u4e00\u4e2a\u75c5\u4eba\u75c5\u4f8b\u3002</li> <li>\u95ee\u9898: \"\u5bf9\u6bd4 WHO \u6307\u5357\u548c\u4e2d\u56fd CSCO \u6307\u5357\uff0c\u5bf9\u8be5\u75c5\u4eba\u7684\u63a8\u8350\u6709\u4f55\u4e0d\u540c\uff1f\"</li> <li>\u91d1\u6807: \u4f60\u7684 KB \u4e2d\u5bf9\u9f50\u597d\u7684 [CN_Action] vs [EN_Action]\u3002</li> <li>\u8003\u5bdf\u70b9: \u8de8\u6587\u5316/\u8de8\u5730\u57df\u7684\u533b\u7597\u77e5\u8bc6\u533a\u5206\u80fd\u529b\u3002</li> </ul>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#4-future-work","title":"4. \u672a\u6765\u6269\u5c55\u4e0e\u521b\u65b0\u70b9 (Future Work)","text":"<ol> <li>\u4ece Text-to-KG \u5230 Text-to-Code:<ul> <li>\u5c1d\u8bd5\u5c06\u6307\u5357\u903b\u8f91\u76f4\u63a5\u7ffb\u8bd1\u6210 Python/Pseudo-code (e.g., <code>def treat_hypertension(patient): ...</code>)\u3002\u8fd9\u6bd4\u56fe\u8c31\u66f4\u9002\u5408\u505a\u4e25\u683c\u7684\u903b\u8f91\u9a8c\u8bc1\u3002</li> </ul> </li> <li>\u591a\u6a21\u6001\u589e\u5f3a:<ul> <li>\u5229\u7528 GPT-4o \u8bc6\u522b NCCN \u6307\u5357\u4e2d\u7684\u539f\u59cb\u6d41\u7a0b\u56fe\u56fe\u7247\uff0c\u4e0e\u6587\u672c\u63d0\u53d6\u7684\u903b\u8f91\u8fdb\u884c\u201c\u53cc\u91cd\u9a8c\u8bc1\uff08Cross-Verification\uff09\u201d\uff0c\u63d0\u9ad8 KB \u51c6\u786e\u7387\u3002</li> </ul> </li> <li>Agent \u6a21\u62df\u573a:<ul> <li>\u65e2\u7136\u6709\u4e86\u903b\u8f91\u5e93\uff0c\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2a \"Doctor Agent\" \u548c \"Patient Agent\" \u7684\u6a21\u62df\u73af\u5883\uff0c\u8ba9 Agent \u4e92\u76f8\u4ea4\u4e92\uff0c\u81ea\u52a8\u751f\u6210\u65e0\u9650\u7684\u5bf9\u8bdd\u8bc4\u6d4b\u6570\u636e\u3002</li> </ul> </li> </ol>"},{"location":"research/ANGEL-lab/week_reports/1208-1214/#5-actionable-to-do","title":"5. \u672c\u5468\u884c\u52a8\u6e05\u5355 (Actionable To-Do)","text":"<ol> <li> \u6570\u636e: \u8dd1\u901a NICE PDF \u7684\u6279\u91cf\u4e0b\u8f7d\u3002</li> <li> \u5de5\u5177: \u8dd1\u901a MinerU/Magic-PDF \u7684 Demo\uff0c\u786e\u8ba4\u80fd\u89e3\u6790\u8868\u683c\u3002</li> <li> \u9a8c\u8bc1: \u624b\u5199\u4e00\u4e2a\u7b80\u6613\u7684 JSON Schema (\u5305\u542b if/then/exception)\uff0c\u7528\u4e00\u4e2a\u7b80\u5355\u7684\u533b\u5b66\u6307\u5357\u7247\u6bb5\u6d4b\u8bd5 LLM \u80fd\u5426\u63d0\u53d6\u6210\u8fd9\u4e2a\u683c\u5f0f\u3002</li> </ol>"}]}